{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Evaluation + Erklärbarkeit\n",
    "\n",
    "## Anforderungen an Projektumsetzung: Evaluation und Interpretation\n",
    "\n",
    "Anforderungen:\n",
    "- Setzen Sie die Aufgabenstellung für ein **Prädiktionsmodell** um -- wahlweise für Ihr Klassifikationsmodell oder Ihr Regressionsmodell aus den Anforderungen aus den entsprechenden Kapiteln.\n",
    "\n",
    "- Definieren Sie für Ihr Modell die Frequenzbaseline bzw. die Mittelwertsbaseline.\n",
    "\n",
    "- Definieren Sie für Ihr Modell eine einfache Vergleichsbaseline.\n",
    "  \n",
    "- Prüfen Sie mittels einer Lernkurve, ob Ihr Modell zu Over- oder Underfitting neigt und evaluieren Sie entsprechend des Ergebnisses ein mächtigeres oder weniger mächtiges Modell. Wenn Ihr Modell weder Over- noch Underfitting zeigt: Herzlichen Glückwunsch, es ist nichts weiter zu tun.\n",
    "\n",
    "- Interpretieren Sie Ihr Modell: Entweder mit Hilfe von LIME oder bei transparenten Algorithmen aufgrund des gelernten Modells selber."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden der Bibliotheken & des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "\n",
    "import importlib\n",
    "import init_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(init_notebook)\n",
    "\n",
    "dataset = init_notebook.get_final_dataset()\n",
    "\n",
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Modells:\n",
    "\n",
    "loaded_feature_model = joblib.load('Modelle/6_Klassifikation/softmax_model_1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setzen Sie die Aufgabenstellung für ein **Prädiktionsmodell** um -- wahlweise für Ihr Klassifikationsmodell oder Ihr Regressionsmodell aus den Anforderungen aus den entsprechenden Kapiteln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Evaluation wird das Klassifikationsmodell [softmax_model_final](Modelle/6_Klassifikation/softmax_model_final.joblib) aus 6_Klassifikation gewählt, da dort einige Experimente durchgeführt wurden und ein relativ guter Wert für die Vorhersage von Rauchern (Percision = 84%) erzielt wurde. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definieren Sie für Ihr Modell die Frequenzbaseline bzw. die Mittelwertsbaseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorausgesagt wird lediglich, ob es sich um einen Nicht-Raucher ODER um einen Raucher/ehemaligen Raucher handelt.\n",
    "# Deshalb werden die Klassen Raucher und ehemalige Raucher zusammengelegt: \n",
    "\n",
    "dataset['Raucher_Status'] = dataset['Raucher_Status'].replace(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>Alter</th>\n",
       "      <th>Größe</th>\n",
       "      <th>Gewicht</th>\n",
       "      <th>Hüftumfang</th>\n",
       "      <th>Systolischer Blutdruck</th>\n",
       "      <th>Diastolischer Blutdruck</th>\n",
       "      <th>Nüchterner Blutzucker</th>\n",
       "      <th>Totale Cholesterin</th>\n",
       "      <th>HDL_Cholesterin</th>\n",
       "      <th>LDL_Cholesterin</th>\n",
       "      <th>Triglycerid</th>\n",
       "      <th>Hämoglobin</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>Trinker</th>\n",
       "      <th>Body-Mass-Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136073</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>67.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569369</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>175</td>\n",
       "      <td>90</td>\n",
       "      <td>96.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341531</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>69.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797039</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>92.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50018</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>86.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>78.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893538</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>75.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683620</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>80</td>\n",
       "      <td>93.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331711</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>72.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831764</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>90.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326405</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>75</td>\n",
       "      <td>105.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792775 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geschlecht  Alter  Größe  Gewicht  Hüftumfang  Systolischer Blutdruck  \\\n",
       "136073           0     35    160       50        67.0                   119.0   \n",
       "569369           1     30    175       90        96.0                   118.0   \n",
       "341531           0     50    155       60        69.0                   150.0   \n",
       "797039           1     60    165       70        92.0                   124.0   \n",
       "50018            0     55    155       60        86.0                   140.0   \n",
       "...            ...    ...    ...      ...         ...                     ...   \n",
       "893538           0     55    155       55        75.0                   108.0   \n",
       "683620           1     30    170       80        93.0                   127.0   \n",
       "331711           0     40    170       65        72.0                   117.0   \n",
       "831764           0     50    160       60        90.0                   116.0   \n",
       "326405           0     60    150       75       105.0                   140.0   \n",
       "\n",
       "        Diastolischer Blutdruck  Nüchterner Blutzucker  Totale Cholesterin  \\\n",
       "136073                     70.0                  100.0               169.0   \n",
       "569369                     76.0                   98.0               210.0   \n",
       "341531                    100.0                  115.0               243.0   \n",
       "797039                     79.0                  106.0               196.0   \n",
       "50018                      81.0                  164.0               165.0   \n",
       "...                         ...                    ...                 ...   \n",
       "893538                     82.0                  131.0               204.0   \n",
       "683620                     81.0                  128.0               222.0   \n",
       "331711                     73.0                  106.0               249.0   \n",
       "831764                     80.0                   92.0               194.0   \n",
       "326405                     82.0                  150.0               218.0   \n",
       "\n",
       "        HDL_Cholesterin  LDL_Cholesterin  Triglycerid  Hämoglobin  SGOT_AST  \\\n",
       "136073             62.0             98.0         47.0        13.9      20.0   \n",
       "569369             43.0            146.0        103.0        15.2      27.0   \n",
       "341531             53.0            159.0        153.0        14.6      34.0   \n",
       "797039             50.0             98.0        242.0        15.8      23.0   \n",
       "50018              55.0             73.0        185.0        12.9      78.0   \n",
       "...                 ...              ...          ...         ...       ...   \n",
       "893538             54.0            137.0         65.0        14.5      22.0   \n",
       "683620             51.0            135.0        177.0        15.7      21.0   \n",
       "331711             58.0            176.0         73.0        10.6      16.0   \n",
       "831764             48.0            117.0        147.0        12.1      17.0   \n",
       "326405             53.0            100.0        324.0        13.9      20.0   \n",
       "\n",
       "        SGOT_ALT  gamma_GTP  Trinker  Body-Mass-Index  \n",
       "136073      21.0       16.0        0            19.53  \n",
       "569369      21.0       17.0        0            29.39  \n",
       "341531      34.0      100.0        1            24.97  \n",
       "797039      25.0       35.0        1            25.71  \n",
       "50018       83.0       66.0        0            24.97  \n",
       "...          ...        ...      ...              ...  \n",
       "893538      17.0       33.0        1            22.89  \n",
       "683620      35.0       24.0        1            27.68  \n",
       "331711      11.0       11.0        0            22.49  \n",
       "831764      12.0       11.0        0            23.44  \n",
       "326405      26.0       19.0        0            33.33  \n",
       "\n",
       "[792775 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=['Raucher_Status']), dataset['Raucher_Status'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Selektion wie in 6_Klassifikation:\n",
    "\n",
    "sf_corr = X_train[['Geschlecht', 'Alter', 'Größe', 'Gewicht', 'Hüftumfang', 'Hämoglobin', 'gamma_GTP', 'Trinker']]\n",
    "\n",
    "sf_corr_test = X_test[['Geschlecht', 'Alter', 'Größe', 'Gewicht', 'Hüftumfang', 'Hämoglobin', 'gamma_GTP', 'Trinker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Baseline): 0.61\n",
      "Precision (Baseline): 0.37\n",
      "Recall (Baseline): 0.61\n",
      "F1 score (Baseline): 0.46\n"
     ]
    }
   ],
   "source": [
    "# Erstelle ein DummyClassifier mit der Strategie 'most_frequent'\n",
    "baseline_model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Trainiere das Basismodell\n",
    "baseline_model.fit(sf_corr, y_train)\n",
    "\n",
    "# Mache Vorhersagen auf dem Testset\n",
    "y_pred_baseline = baseline_model.predict(sf_corr_test)\n",
    "\n",
    "# Evaluationsmetriken berechnen\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "precision_baseline = precision_score(y_test, y_pred_baseline, average='weighted')\n",
    "recall_baseline = recall_score(y_test, y_pred_baseline, average='weighted')\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline, average='weighted')\n",
    "\n",
    "# Confusion Matrix erstellen und anzeigen\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', xticklabels=dataset['Raucher_Status'].unique(), yticklabels=dataset['Raucher_Status'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - Baseline')\n",
    "plt.show()\n",
    "\n",
    "# Ausgabe der Metriken\n",
    "print(f'Accuracy (Baseline): {accuracy_baseline:.2f}')\n",
    "print(f'Precision (Baseline): {precision_baseline:.2f}')\n",
    "print(f'Recall (Baseline): {recall_baseline:.2f}')\n",
    "print(f'F1 score (Baseline): {f1_baseline:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Funktion DummyClassifier(strategy='most_frequent') wird stets die am häufigsten vorkommende Klasse prädiziert, wodurch eine Frequenzbaseline geschaffen wird.\n",
    "\n",
    "Das Ergebnis der Metriken dieses Modells ist deutlich schlechter als die Ergebnisse unseres Modells [softmax_model_final.joblib](Modelle/6_Klassifikation/softmax_model_final.joblib) aus 6_Klassifikation:\n",
    "\n",
    "Accuracy: 0.83\n",
    "\n",
    "Precision: 0.84\n",
    "\n",
    "Recall weighted: 0.83\n",
    "\n",
    "F1 score: 0.83\n",
    "\n",
    "Es muss jedoch dazugesagt werden, dass sich die beiden Klassen sehr ähnlich verteilen (60 / 40), was es schwierig macht, bei einer Frequenzbasislinie gute Metriken zu erzielen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definieren Sie für Ihr Modell eine einfache Vergleichsbaseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstelle einer Pipeline ein manuelle Initiaisierung. \n",
    "Wie im Skript wird eine NB-Klassifikation genutzt, da wir die SoftmaxRegression auch zum Klassifizieren nutzten.\n",
    "Als Features werden die Selben wie beim Ausgangsmodell (bestes Modell) verwendet.\n",
    "Ergebnis besser als die Frequenzbaseline, allerdings schlechter als das beste Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.79      0.82    120332\n",
      "         2.0       0.70      0.78      0.74     77862\n",
      "\n",
      "    accuracy                           0.79    198194\n",
      "   macro avg       0.78      0.79      0.78    198194\n",
      "weighted avg       0.79      0.79      0.79    198194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialisierung des Naive Bayes-Klassifikators\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Training des Modells\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf dem Testset\n",
    "Y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluierung der Genauigkeit\n",
    "accuracy = accuracy_score(y_test, Y_pred)\n",
    "\n",
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weieres Baseline Modell. Diesesmal mit weiterer Features Selektion. Allerdings Fehler beim konviergieren. Daher Ergebnisse mit Vorsicht zu genießen.\n",
    "\n",
    "Eventuell löschen wir das auch wieder vor der Abgabe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.73      0.82    120332\n",
      "         2.0       0.69      0.93      0.79     77862\n",
      "\n",
      "    accuracy                           0.81    198194\n",
      "   macro avg       0.82      0.83      0.81    198194\n",
      "weighted avg       0.84      0.81      0.81    198194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_pipeline = Pipeline(steps=[\n",
    "                ('feature_selection',\n",
    "                 SelectFromModel(estimator=LinearSVC(dual=False,\n",
    "                                                     penalty='l1'), threshold='mean')),\n",
    "                ('classifier', GaussianNB())])\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Lerner auf den Testdaten evaluieren\n",
    "\n",
    "dev_labels = baseline_pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prüfen Sie mittels einer Lernkurve, ob Ihr Modell zu Over- oder Underfitting neigt und evaluieren Sie entsprechend des Ergebnisses ein mächtigeres oder weniger mächtiges Modell. Wenn Ihr Modell weder Over- noch Underfitting zeigt: Herzlichen Glückwunsch, es ist nichts weiter zu tun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainigsdaten weiter unterteilen in Evaluierungsdaten und TEsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m softmax_model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Lernkurve plotten - läuft eine Weile!\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43minit_notebook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_learning_curves\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoftmax_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\imanu\\HfT - Master\\1. Semester\\DataAnalytics\\Projekt\\Anforderungen\\init_notebook.py:148\u001b[0m, in \u001b[0;36mplot_learning_curves\u001b[1;34m(model, X_train, y_train, X_dev, y_dev)\u001b[0m\n\u001b[0;32m    146\u001b[0m train_fs, dev_fs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m--> 148\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     y_train_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train[:m])\n\u001b[0;32m    150\u001b[0m     y_dev_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_dev)\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    451\u001b[0m ]\n\u001b[1;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    461\u001b[0m     solver,\n\u001b[0;32m    462\u001b[0m     opt_res,\n\u001b[0;32m    463\u001b[0m     max_iter,\n\u001b[0;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    465\u001b[0m )\n\u001b[0;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:279\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 279\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    286\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[1;32mc:\\Users\\imanu\\anaconda3\\lib\\site-packages\\sklearn\\_loss\\loss.py:253\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    251\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lerner vorbereiten: SVM\n",
    "softmax_model = LogisticRegression()\n",
    "\n",
    "# Lernkurve plotten - läuft eine Weile!\n",
    "\n",
    "init_notebook.plot_learning_curves(softmax_model, X_train, y_train, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretieren Sie Ihr Modell: Entweder mit Hilfe von LIME oder bei transparenten Algorithmen aufgrund des gelernten Modells selber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
